<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.15"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>CrashTestDummiesDoc: Kinect2 Calibration</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">CrashTestDummiesDoc
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.15 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Kinect2 Calibration </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Maintainer</h2>
<ul>
<li><a href="https://ai.uni-bremen.de/team/thiemo_wiedemeyer">Thiemo Wiedemeyer</a> &lt;<a href="#" onclick="location.href='mai'+'lto:'+'wie'+'de'+'mey'+'er'+'@cs'+'.u'+'ni-'+'br'+'eme'+'n.'+'de'; return false;">wiede<span style="display: none;">.nosp@m.</span>meye<span style="display: none;">.nosp@m.</span>r@cs.<span style="display: none;">.nosp@m.</span>uni-<span style="display: none;">.nosp@m.</span>breme<span style="display: none;">.nosp@m.</span>n.de</a>&gt;, <a href="http://ai.uni-bremen.de/">Institute for Artificial Intelligence</a>, University of Bremen</li>
</ul>
<p><em>Note:</em> <em><b>Please use the GitHub issues</b></em> <em>for questions and problems regarding the iai_kinect2 package and its components.</em> <em><b>Do not write emails.</b></em></p>
<h2>Description</h2>
<p>This tool uses OpenCV to calibrate two cameras to each other. It is specially designed for the Kinect One. It uses chess or circle boards.</p>
<h2>Dependencies</h2>
<ul>
<li>ROS Hydro/Indigo</li>
<li>OpenCV</li>
</ul>
<p><em>for the ROS packages look at the package.xml</em></p>
<h2>Usage</h2>
<div class="fragment"><div class="line">kinect2_calibration [options]</div><div class="line">  name: &#39;any string&#39; equals to the kinect2_bridge topic base name</div><div class="line">  mode: &#39;record&#39; or &#39;calibrate&#39;</div><div class="line">  source: &#39;color&#39;, &#39;ir&#39;, &#39;sync&#39;, &#39;depth&#39;</div><div class="line">  board:</div><div class="line">    &#39;circle&lt;WIDTH&gt;x&lt;HEIGHT&gt;x&lt;SIZE&gt;&#39;  for symmetric circle grid</div><div class="line">    &#39;acircle&lt;WIDTH&gt;x&lt;HEIGHT&gt;x&lt;SIZE&gt;&#39; for asymmetric circle grid</div><div class="line">    &#39;chess&lt;WIDTH&gt;x&lt;HEIGHT&gt;x&lt;SIZE&gt;&#39;   for chessboard pattern</div><div class="line">  distortion model: &#39;rational&#39; for using model with 8 instead of 5 coefficients</div><div class="line">  output path: &#39;-path &lt;PATH&gt;&#39;</div></div><!-- fragment --><h2>Key bindings</h2>
<p>Windows:</p><ul>
<li><code>ESC</code>, <code>q</code>: Quit</li>
<li><code>SPACE</code>, <code>s</code>: Save the current image for calibration</li>
<li><code>l</code>: decrease min and max value for IR value rage</li>
<li><code>h</code>: increase min and max value for IR value rage</li>
<li><code>1</code>: decrease min value for IR value rage</li>
<li><code>2</code>: increase min value for IR value rage</li>
<li><code>3</code>: decrease max value for IR value rage</li>
<li><code>4</code>: increase max value for IR value rage</li>
</ul>
<p>Terminal:</p><ul>
<li><code>CRTL</code>+<code>c</code>: Quit</li>
</ul>
<h2>Calibration patterns</h2>
<p>Any chessboard pattern or symmetric or asymmetric circle grid should work. Three different chessboard patterns are located inside the <code>kinect2_calibration/patterns</code> folder:</p><ul>
<li><a href="patterns/chess5x7x0.03.pdf">chess5x7x0.03.pdf</a></li>
<li><a href="patterns/chess7x9x0.025.pdf">chess7x9x0.025.pdf</a></li>
<li><a href="patterns/chess9x11x0.02.pdf">chess9x11x0.02.pdf</a></li>
</ul>
<p>Other patterns are available at OpenCV:</p><ul>
<li><a href="http://docs.opencv.org/2.4.2/_downloads/pattern.png">Chessboard pattern</a></li>
<li><a href="http://docs.opencv.org/2.4.2/_downloads/acircles_pattern.png">Asymmetric circle grid</a></li>
</ul>
<p>The standard board is a 7x6 0.108m chessboard from the PR2. But any other board can be specified with as parameter. For example a circle board with 8x7 circles in 0.02m distance between them <code>rosrun kinect2_calibration kinect2_calibration record color circle8x7x0.02</code>.</p>
<p>Recently, to calibrate our sensors, we have used the chess5x7x0.03 pattern, as it can be printed easily on a good laser printer on A4 paper.</p>
<h2>Calibrating the Kinect One</h2>
<p><em>Recommended preparation:</em></p><ul>
<li>Print your calibration pattern (for the examples, we used chess5x7x0.03) and glue it to a flat object. It is very important that the calibration pattern is very flat. Also, check with a caliper that the distance between the features of the printed pattern is correct. Sometimes printers scale the document, and the calibration won't work. For the mentioned pattern, the distance between intersections of black and white corners should be 3cm exactly.</li>
<li>Get two tripods, one for holding the calibration pattern, and another one for holding the kinect2 sensor. Ideally, the tripod for the kinect2 will have a ball head, to allow you to move it easily and lock it in place before you take an image. It is very important that the sensor is stable (and the image is clear and not blurred) before you take an image. The tripod will specially help you to make sure that the sensor has not moved between the moment the IR and the RGB images are taken.</li>
<li>When recording images for all the steps indicated below (RGB, IR, SYNC), start the recording program, then press spacebar to record each image. The calibration pattern should be detected (indicated by color lines overlayed on the calibration pattern), and the image should be clear and stable.</li>
<li>It is recommended to take images that show the calibration pattern in all areas of the image, and with different orientations of the pattern (tilting the pattern relative to the plane of the image), and at least two distances. So you can easily reach 100 images per calibration set.</li>
<li>We normally start at a short distance, where the calibration pattern covers most of the image, there we take several pictures tilting the calibration pattern vertically, then horizontally. Imagine a ray coming out of the camera sensor, this makes sure that you have images where the calibration pattern is not perpendicular to that ray.</li>
<li>Then we move the calibration pattern further away, and for different orientations (tilting) of the pattern, we take many images so that we calibration pattern is present around most of the camera image. For example, at first the calibration pattern is on the left upper corner. Then on the next image on the upper middle, then on the upper right corner. Then some images where the calibration pattern is in the middle vertically, etc...</li>
</ul>
<p><em>Typical calibration setup</em> <img src="https://ai.uni-bremen.de/_media/kinect2_calibration_setup_small.jpg" alt="kinect2_calibration_setup_small.jpg" class="inline"/>
<p><em>Detailed steps:</em></p>
<p>0. If you haven't already, start the kinect2_bridge with a low number of frames per second (to make it easy on your CPU): <code>rosrun kinect2_bridge kinect2_bridge _fps_limit:=2</code></p><ol type="1">
<li>create a directory for your calibration data files, for example: <code>mkdir ~/kinect_cal_data; cd ~/kinect_cal_data</code></li>
<li>Record images for the color camera: <code>rosrun kinect2_calibration kinect2_calibration chess5x7x0.03 record color</code></li>
<li>Calibrate the intrinsics: <code>rosrun kinect2_calibration kinect2_calibration chess5x7x0.03 calibrate color</code></li>
<li>Record images for the ir camera: <code>rosrun kinect2_calibration kinect2_calibration chess5x7x0.03 record ir</code></li>
<li>Calibrate the intrinsics of the ir camera: <code>rosrun kinect2_calibration kinect2_calibration chess5x7x0.03 calibrate ir</code></li>
<li>Record images on both cameras synchronized: <code>rosrun kinect2_calibration kinect2_calibration chess5x7x0.03 record sync</code></li>
<li>Calibrate the extrinsics: <code>rosrun kinect2_calibration kinect2_calibration chess5x7x0.03 calibrate sync</code></li>
<li>Calibrate the depth measurements: <code>rosrun kinect2_calibration kinect2_calibration chess5x7x0.03 calibrate depth</code></li>
<li>Find out the serial number of your kinect2 by looking at the first lines printed out by the kinect2_bridge. The line looks like this: <code>device serial: 012526541941</code></li>
<li>Create the calibration results directory in kinect2_bridge/data/$serial: <code>roscd kinect2_bridge/data; mkdir 012526541941</code></li>
<li>Copy the following files from your calibration directory (~/kinect_cal_data) into the directory you just created: <code>calib_color.yaml calib_depth.yaml calib_ir.yaml calib_pose.yaml</code></li>
<li>Restart the kinect2_bridge and be amazed at the better data.</li>
</ol>
<h2>Calibration of the depth measurements</h2>
<p>I did some tests on the measured and the computed distance based on the detected chess board. It seems like the Kinect2 (or at least the Kinect2s I am using) has a static offset of around 24 mm. As shown in the following images, one can see, that the difference between measured and computed distance is unrelated to the x and y coordinates of the pixel and also unrelated to the distance.</p>
<img src="http://ai.uni-bremen.de/wiki/_media/software/plot.png" alt="plot.png" class="inline"/>
 <img src="http://ai.uni-bremen.de/wiki/_media/software/plot_x.png" alt="plot_x.png" class="inline"/>
 <img src="http://ai.uni-bremen.de/wiki/_media/software/plot_y.png" alt="plot_y.png" class="inline"/>
 <img src="http://ai.uni-bremen.de/wiki/_media/software/plot_xy.png" alt="plot_xy.png" class="inline"/>
<p>For the images above ~400 images of a 4x5x0.03 chessboard in different orientations, distances and image positions were used. The code for computing the depth offset is added to the calibration tool.</p>
<h3>GNUPlot</h3>
<p>The depth calibration creates a file named <code>plot.dat</code> inside the calibration folder. This files contains the results of the calibration in 5 columns: x, y, computed depth, measured depth, difference between computed and measured depth.</p>
<ul>
<li>Difference between measured/computed distance</li>
</ul>
<div class="fragment"><div class="line">set xlabel &quot;Measured distance&quot;</div><div class="line">set ylabel &quot;Computed distance&quot;</div><div class="line">plot &#39;plot.dat&#39; using 3:4 with dots title &quot;Difference between measured/computed distance&quot;</div></div><!-- fragment --><ul>
<li>Difference relative to x coordinate</li>
</ul>
<div class="fragment"><div class="line">set xlabel &quot;X&quot;</div><div class="line">set ylabel &quot;Distance difference&quot;</div><div class="line">plot &#39;plot.dat&#39; using 1:5 with dots title &quot;Difference relative to X-coordinate&quot;</div></div><!-- fragment --><ul>
<li>Difference relative to y coordinate</li>
</ul>
<div class="fragment"><div class="line">set xlabel &quot;Y&quot;</div><div class="line">set ylabel &quot;Distance difference&quot;</div><div class="line">plot &#39;plot.dat&#39; using 2:5 with dots title &quot;Difference relative to Y-coordinate&quot;</div></div><!-- fragment --><ul>
<li>Difference relative to XY-coordinate</li>
</ul>
<div class="fragment"><div class="line">set xlabel &quot;X&quot;</div><div class="line">set ylabel &quot;Y&quot;</div><div class="line">set zlabel &quot;Distance difference&quot;</div><div class="line">splot &#39;plot.dat&#39; using 1:2:5 with dots palette title &quot;Difference relative to XY-coordinate&quot;</div></div><!-- fragment --><h2>Example results</h2>
<p>Example calibration results can be found in the directory <a href="../kinect2_bridge/data">kinect2_bridge/data/</a>.</p>
<p>The following images were made before and after the calibration, using the kinect2 viewer.</p><ul>
<li>For the superimposed images: <code>rosrun kinect2_viewer kinect2_viewer hd image</code></li>
<li>For the point cloud images: <code>rosrun kinect2_viewer kinect2_viewer hd cloud</code></li>
<li>For the superimposed and point cloud images: <code>rosrun kinect2_viewer kinect2_viewer hd both</code></li>
</ul>
<p>raw here stands for raw data transmission aka uncompressed.</p>
<p>Uncalibrated rectified images (depth and RGB superimposed): <img src="https://ai.uni-bremen.de/_media/kinect2_raw_nocalib.png" alt="kinect2_cloud_calib" class="inline"/>
<p>Calibrated rectified images (depth and RGB superimposed): <img src="https://ai.uni-bremen.de/_media/kinect2_raw_calib.png" alt="kinect2_cloud_calib" class="inline"/>
<p>Uncalibrated depth cloud: <img src="https://ai.uni-bremen.de/_media/kinect2_cloud_nocalib.png" alt="kinect2_cloud_calib" class="inline"/>
<p>Calibrated depth cloud: <img src="https://ai.uni-bremen.de/_media/kinect2_cloud_calib.png" alt="kinect2_cloud_calib" class="inline"/>
<p>Note how the color is now correctly applied on the depth data. This is specially evident around strong edges, like the edge of the white column on the left. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.15
</small></address>
</body>
</html>
